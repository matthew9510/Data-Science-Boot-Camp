{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:SteelBlue\">Lesson:</span> Building an ML Pipeline</h1>\n",
    "<hr>\n",
    "We've talked about the process of training a model already which is a failry straight forward process when were talking about a single model, with predefined HyperParameters.\n",
    "\n",
    "However, in most real life situations we DO NOT know what models may be the best suited for the task at hand, let alone the appropriate hyperparameters for each model. \n",
    "\n",
    "**The Solution?**\n",
    "\n",
    "We will write a series of loops that use *Cross-Validation* to \"test\" each model, including every combination of relevant hyperparameters â€”for each model, in order to discern which configuration is the most effective.\n",
    "\n",
    "**Relevant topics for this section on Building Pipelines:**\n",
    "1. Dictionaries\n",
    "2. Looping\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PyData Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for DataFrames\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns',None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Pickle for saving model files\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SKLearn Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logistic Regression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import RandomForestClassifier and GradientBoostingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries to make Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import make_pipeline from sklearn.pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# import StandardScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import GridSearchCV from sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import roc_curve and auc from sklearn.metrics\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/titanic_abt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>FamilySize_1</th>\n",
       "      <th>FamilySize_2</th>\n",
       "      <th>FamilySize_3</th>\n",
       "      <th>FamilySize_4</th>\n",
       "      <th>FamilySize_5</th>\n",
       "      <th>FamilySize_6</th>\n",
       "      <th>FamilySize_7</th>\n",
       "      <th>FamilySize_8</th>\n",
       "      <th>FamilySize_11</th>\n",
       "      <th>FareCat_0</th>\n",
       "      <th>FareCat_1</th>\n",
       "      <th>FareCat_2</th>\n",
       "      <th>FareCat_3</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "      <th>AgeBand_0</th>\n",
       "      <th>AgeBand_1</th>\n",
       "      <th>AgeBand_2</th>\n",
       "      <th>AgeBand_3</th>\n",
       "      <th>AgeBand_4</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Gender  Alone  Pclass_1  Pclass_2  Pclass_3  FamilySize_1  \\\n",
       "0         0       0      0         0         0         1             0   \n",
       "1         1       1      0         1         0         0             0   \n",
       "2         1       1      1         0         0         1             1   \n",
       "3         1       1      0         1         0         0             0   \n",
       "4         0       0      1         0         0         1             1   \n",
       "\n",
       "   FamilySize_2  FamilySize_3  FamilySize_4  FamilySize_5  FamilySize_6  \\\n",
       "0             1             0             0             0             0   \n",
       "1             1             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             1             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   FamilySize_7  FamilySize_8  FamilySize_11  FareCat_0  FareCat_1  FareCat_2  \\\n",
       "0             0             0              0          1          0          0   \n",
       "1             0             0              0          0          0          0   \n",
       "2             0             0              0          0          1          0   \n",
       "3             0             0              0          0          0          0   \n",
       "4             0             0              0          0          1          0   \n",
       "\n",
       "   FareCat_3  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Other  \\\n",
       "0          0             0           0         1          0            0   \n",
       "1          1             0           0         0          1            0   \n",
       "2          0             0           1         0          0            0   \n",
       "3          1             0           0         0          1            0   \n",
       "4          0             0           0         1          0            0   \n",
       "\n",
       "   AgeBand_0  AgeBand_1  AgeBand_2  AgeBand_3  AgeBand_4  Embarked_C  \\\n",
       "0          0          1          0          0          0           0   \n",
       "1          0          0          0          1          0           1   \n",
       "2          0          1          0          0          0           0   \n",
       "3          0          0          0          1          0           0   \n",
       "4          0          0          0          1          0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into `X` and `y` sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shape` of `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shape` of `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split `X` and `y` into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to split both the `X` and `y` datasets into Train and Test sets. This will result in 4 datasets total.**\n",
    "\n",
    "```(X_train, X_test, y_train, y_test)```\n",
    "\n",
    "> **`X`:** `X_train` and `X_test`\n",
    "\n",
    "> **`y`:** `y_train` and `y_test`\n",
    "\n",
    "The **Train Set** is the set that we will operform further splits on, during the cross-validation step. The motivation for this is to find the best combination of model and hyperparameters, which we can only achieve by running performance metrics on every possible combination of Model and Hyperparameters.\n",
    "\n",
    "The **Test Set** will remain untouched until after the cross-validation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_test_split()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will pass in the following values to `train_test_split`\n",
    "```python \n",
    "X\n",
    "y\n",
    "test_size = 0.2, \n",
    "stratify = df['Outcome'], \n",
    "random_state = 123\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify = y, \n",
    "    random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `print` length of `X_train` and `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 712\n",
      "X_test: 179\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", len(X_train)) \n",
    "print(\"X_test:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `print` length of `y_train` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: 712\n",
      "y_test: 179\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train:\", len(y_train)) \n",
    "print(\"y_test:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both **Train** sets, **X_train and y_train**, should have the **same number of rows**\n",
    "\n",
    "Both **Test** sets, **X_test and y_test**, should also have the **same number of rows**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Pipeline Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline dictionary can contain as many models as your heart's content. We use this approach to automate the process of fitting a model, predicting labels, and finally testing model accuracy.\n",
    "\n",
    "This will all be done with the SKlearn model_selection function **GridSearchCV()** which expects at least two arguments a **Pipeline** dictionary and a **Hyperparameters** dictionary, with matching keys!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dict = {\n",
    "    \"l1\" : make_pipeline(StandardScaler(), LogisticRegression(penalty=\"l1\", random_state = 123)),\n",
    "    \"l2\" : make_pipeline(StandardScaler(), LogisticRegression(penalty=\"l2\", random_state = 123)),\n",
    "    \"rf\" : make_pipeline(StandardScaler(), RandomForestClassifier(random_state = 123)),\n",
    "    \"gb\" : make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state = 123)),\n",
    "    \"kn\" : make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 1</span> - Dictionary Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through pipeline dict to print out the type of object that is associated with every model \"key.\"\n",
    "\n",
    "Remember dictionaries are set up like:\n",
    "```python \n",
    "some_dict = {\n",
    "    key1 : val1\n",
    "    key2 : val2\n",
    "}```\n",
    "\n",
    "\n",
    "**Hint:** I want you to **print every key** and the **type of every matching value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do work here so you don't erase the answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: <class 'sklearn.pipeline.Pipeline'>\n",
      "l2: <class 'sklearn.pipeline.Pipeline'>\n",
      "rf: <class 'sklearn.pipeline.Pipeline'>\n",
      "gb: <class 'sklearn.pipeline.Pipeline'>\n",
      "kn: <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for key, val in pipeline_dict.items():\n",
    "    print(key + \":\", type(val))\n",
    "    \n",
    "# Your code should output this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a Hyperparameters Nested-Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following describes the goal for this section, however we will begin with some exercises to help understand the concept of a nested dictionary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Final Hyperparameter Dictionary: `hp_dict`**\n",
    "\n",
    "> Every `key` in `hp_dict` will match the keys from `pipeline_dict`.\n",
    "\n",
    "> Every `value` in `hp_dict` will be a dictionary.\n",
    "\n",
    "**Nested Dictionaries inside `hp_dict`**\n",
    "\n",
    "> Every `key` in each nested `dict` will be a different hyperparameter that needs tuning.\n",
    "\n",
    "> Every `value` will hold a range of values that each particular hyperparameter can take on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of an `hp_dict` with values for 2 different models**\n",
    "\n",
    "*Notice that the `values` of `hp_dict` are surrounded by `{}`, this means that they are themselves dictionaries!*\n",
    "```python \n",
    "hp_dict = {\n",
    "    'kn':{\"kneighborsclassifier__n_neighbors\" : np.arange(1,11)}\n",
    "    'l1':{\"logisticregression__C\" : np.linspace(1e-4, 1e4, 10)}\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 2</span> - Performing Action during Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop through `pipeline_dict` to print out the `type` of object that is associated with the `get_params()` method, for every model \"key.\"**\n",
    "\n",
    "**Remember:** Dictionaries in Python are set up like this:\n",
    "```python \n",
    "some_dict = {\n",
    "    key1 : val1\n",
    "    key2 : val2\n",
    "}```\n",
    "\n",
    "\n",
    "**Hint:** I want you to **`print` every `key`** and the **`type` of object that results from calling the `get_params()` method on every matching `value`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 <class 'dict'>\n",
      "l2 <class 'dict'>\n",
      "rf <class 'dict'>\n",
      "gb <class 'dict'>\n",
      "kn <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for key, val in pipeline_dict.items():\n",
    "    print(key, type(val.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What type of object does get_params() return? \n",
    "What could we do to said object?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 3</span> - Nested Dictionary Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since `get_params()` results in a `dict` object we can use `.items()` to loop through every `key` `value` pair inside of each parameter `dict`!**\n",
    "\n",
    "There is nothing stopping us from nesting a second for loop from inside a for loop!\n",
    "\n",
    "This is one of the harder concepts to understand at first, but once you get it, you'll realize how straightforward the process really is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory None\n",
      "steps [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))]\n",
      "standardscaler StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "logisticregression LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "standardscaler__copy True\n",
      "standardscaler__with_mean True\n",
      "standardscaler__with_std True\n",
      "logisticregression__C 1.0\n",
      "logisticregression__class_weight None\n",
      "logisticregression__dual False\n",
      "logisticregression__fit_intercept True\n",
      "logisticregression__intercept_scaling 1\n",
      "logisticregression__max_iter 100\n",
      "logisticregression__multi_class warn\n",
      "logisticregression__n_jobs None\n",
      "logisticregression__penalty l1\n",
      "logisticregression__random_state 123\n",
      "logisticregression__solver warn\n",
      "logisticregression__tol 0.0001\n",
      "logisticregression__verbose 0\n",
      "logisticregression__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))]\n",
      "standardscaler StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "logisticregression LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "standardscaler__copy True\n",
      "standardscaler__with_mean True\n",
      "standardscaler__with_std True\n",
      "logisticregression__C 1.0\n",
      "logisticregression__class_weight None\n",
      "logisticregression__dual False\n",
      "logisticregression__fit_intercept True\n",
      "logisticregression__intercept_scaling 1\n",
      "logisticregression__max_iter 100\n",
      "logisticregression__multi_class warn\n",
      "logisticregression__n_jobs None\n",
      "logisticregression__penalty l2\n",
      "logisticregression__random_state 123\n",
      "logisticregression__solver warn\n",
      "logisticregression__tol 0.0001\n",
      "logisticregression__verbose 0\n",
      "logisticregression__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False))]\n",
      "standardscaler StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "randomforestclassifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "standardscaler__copy True\n",
      "standardscaler__with_mean True\n",
      "standardscaler__with_std True\n",
      "randomforestclassifier__bootstrap True\n",
      "randomforestclassifier__class_weight None\n",
      "randomforestclassifier__criterion gini\n",
      "randomforestclassifier__max_depth None\n",
      "randomforestclassifier__max_features auto\n",
      "randomforestclassifier__max_leaf_nodes None\n",
      "randomforestclassifier__min_impurity_decrease 0.0\n",
      "randomforestclassifier__min_impurity_split None\n",
      "randomforestclassifier__min_samples_leaf 1\n",
      "randomforestclassifier__min_samples_split 2\n",
      "randomforestclassifier__min_weight_fraction_leaf 0.0\n",
      "randomforestclassifier__n_estimators warn\n",
      "randomforestclassifier__n_jobs None\n",
      "randomforestclassifier__oob_score False\n",
      "randomforestclassifier__random_state 123\n",
      "randomforestclassifier__verbose 0\n",
      "randomforestclassifier__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingclassifier', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=123,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False))]\n",
      "standardscaler StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "gradientboostingclassifier GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=123,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "standardscaler__copy True\n",
      "standardscaler__with_mean True\n",
      "standardscaler__with_std True\n",
      "gradientboostingclassifier__criterion friedman_mse\n",
      "gradientboostingclassifier__init None\n",
      "gradientboostingclassifier__learning_rate 0.1\n",
      "gradientboostingclassifier__loss deviance\n",
      "gradientboostingclassifier__max_depth 3\n",
      "gradientboostingclassifier__max_features None\n",
      "gradientboostingclassifier__max_leaf_nodes None\n",
      "gradientboostingclassifier__min_impurity_decrease 0.0\n",
      "gradientboostingclassifier__min_impurity_split None\n",
      "gradientboostingclassifier__min_samples_leaf 1\n",
      "gradientboostingclassifier__min_samples_split 2\n",
      "gradientboostingclassifier__min_weight_fraction_leaf 0.0\n",
      "gradientboostingclassifier__n_estimators 100\n",
      "gradientboostingclassifier__n_iter_no_change None\n",
      "gradientboostingclassifier__presort auto\n",
      "gradientboostingclassifier__random_state 123\n",
      "gradientboostingclassifier__subsample 1.0\n",
      "gradientboostingclassifier__tol 0.0001\n",
      "gradientboostingclassifier__validation_fraction 0.1\n",
      "gradientboostingclassifier__verbose 0\n",
      "gradientboostingclassifier__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform'))]\n",
      "standardscaler StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "kneighborsclassifier KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "standardscaler__copy True\n",
      "standardscaler__with_mean True\n",
      "standardscaler__with_std True\n",
      "kneighborsclassifier__algorithm auto\n",
      "kneighborsclassifier__leaf_size 30\n",
      "kneighborsclassifier__metric minkowski\n",
      "kneighborsclassifier__metric_params None\n",
      "kneighborsclassifier__n_jobs None\n",
      "kneighborsclassifier__n_neighbors 5\n",
      "kneighborsclassifier__p 2\n",
      "kneighborsclassifier__weights uniform\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key, val in pipeline_dict.items():\n",
    "    for k, v in val.get_params().items():\n",
    "        print(k, v)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 4</span> - Making individual HyperParameter Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for L1 aka \"LASSO\" Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will to provide a range of values for the `logisticregression__C` hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be `10` *equally spaced values* between \n",
    "> `1e-4` or 0.0001 and `1e4` or 10,000\n",
    "\n",
    "**Hint**: What numpy *generator* function allows us to create a range of **equally spaced values**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linspace(1e-4, 1e4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_hyperparameters = { \n",
    "    \"logisticregression__C\" : np.linspace(1e-4, 1e4, 10) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for L2 aka \"Ridge\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(1e-4, 1e4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_hyperparameters = { \n",
    "    \"logisticregression__C\" : np.linspace(1e-4, 1e4, 10) \n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyperparameters = { \n",
    "        \"randomforestclassifier__n_estimators\" : [10, 100, 200], \n",
    "        \"randomforestclassifier__max_features\" : [\"auto\", \"sqrt\",\"log2\",None]  \n",
    "}     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_hyperparameters = {\n",
    "        \"gradientboostingclassifier__n_estimators\" : [10, 100, 200],\n",
    "        \"gradientboostingclassifier__learning_rate\" : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        \"gradientboostingclassifier__max_depth\" : [1, 3, 5, 7, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_hyperparameters = { \"kneighborsclassifier__n_neighbors\" : \n",
    "                      np.arange(1,11)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5a</span> - Assemble `hp_dict`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    'l1' : l1_hyperparameters,\n",
    "    'l2' : l2_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "    'kn' : kn_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5b</span> - Loop throu `hp_dict` to verify work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a for loop that prints out each `key` and `value` in `hp_dict`, no need to make it look fancy like me, can be done in 3 lines of code. My example took 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1\n",
      "---------\n",
      "logisticregression__C :\n",
      "0.0001\n",
      "1111.1112\n",
      "2222.2223000000004\n",
      "3333.3334000000004\n",
      "4444.4445000000005\n",
      "5555.555600000001\n",
      "6666.666700000001\n",
      "7777.777800000001\n",
      "8888.8889\n",
      "10000.0\n",
      "l2\n",
      "---------\n",
      "logisticregression__C :\n",
      "0.0001\n",
      "1111.1112\n",
      "2222.2223000000004\n",
      "3333.3334000000004\n",
      "4444.4445000000005\n",
      "5555.555600000001\n",
      "6666.666700000001\n",
      "7777.777800000001\n",
      "8888.8889\n",
      "10000.0\n",
      "rf\n",
      "---------\n",
      "randomforestclassifier__n_estimators :\n",
      "10\n",
      "100\n",
      "200\n",
      "randomforestclassifier__max_features :\n",
      "auto\n",
      "sqrt\n",
      "log2\n",
      "None\n",
      "gb\n",
      "---------\n",
      "gradientboostingclassifier__n_estimators :\n",
      "10\n",
      "100\n",
      "200\n",
      "gradientboostingclassifier__learning_rate :\n",
      "0.0001\n",
      "0.001\n",
      "0.01\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "gradientboostingclassifier__max_depth :\n",
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "kn\n",
      "---------\n",
      "kneighborsclassifier__n_neighbors :\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# 3 lines of code\n",
    "for model_name, model_hyper_param_dict in hp_dict.items():\n",
    "    print(model_name)\n",
    "    print(\"---------\")\n",
    "    for hyper_param, hyper_param_value in model_hyper_param_dict.items():\n",
    "        print(hyper_param, \":\")\n",
    "        for val in hyper_param_value:\n",
    "            print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both a `Pipeline_dict` and a `hp_dict` we can build the loop that will handle cross-validation for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 6</span> - Write a loop that uses `GridSearchCV()` to fit models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb has been fitted\n",
      "kn has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipeline_dict.items():\n",
    "    \n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hp_dict[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate metrics\n",
    "\n",
    "Finally, it's time to evaluate our models and pick the best one.\n",
    "\n",
    "<br>\n",
    "\n",
    "**First, display the <code style=\"color:steelblue\">best\\_score_</code> attribute for each fitted model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 7</span> - Access `best_score_` attribute for each cross-validation object in `fitted_models`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint: this is what it looks like to access the `best_score_` attribute for a single member of `fitted_models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8174157303370787"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['l1'].best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your for-loop here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 0.8174157303370787\n",
      "l2 0.8174157303370787\n",
      "rf 0.8202247191011236\n",
      "gb 0.8286516853932584\n",
      "kn 0.8216292134831461\n"
     ]
    }
   ],
   "source": [
    "for model_name, cv_obj in fitted_models.items():\n",
    "    print(model_name, cv_obj.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb : 0.8286516853932584\n"
     ]
    }
   ],
   "source": [
    "best_model_name = \"\"\n",
    "best_model_value = 0\n",
    "for model_name, cv_obj in fitted_models.items():\n",
    "    model_score = cv_obj.best_score_\n",
    "    if model_score > best_model_value:\n",
    "        best_model_name = model_name\n",
    "        best_model_value = model_score\n",
    "print(best_model_name, \":\", best_model_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:331: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y_pred = fitted_models[best_model_name].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 14]\n",
      " [20 49]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "class_labels = [\"Died\",\"Survived\"]\n",
    "_ = print_confusion_matrix(confusion_matrix = cm, class_names = class_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       110\n",
      "           1       0.78      0.71      0.74        69\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       179\n",
      "   macro avg       0.80      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC_Curve and Area_Under_ROC_Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:381: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = fitted_models[best_model_name].predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get False Positve / True Positive Rates and Matching Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FalsePositiveRate</th>\n",
       "      <th>TruePositiveRate</th>\n",
       "      <th>Thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.943997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.943997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.939609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.927748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.925138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.919399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.916405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.908148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.893059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.857308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.837453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.832171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.798673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.790673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.738398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.684879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.682558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.063636</td>\n",
       "      <td>0.063636</td>\n",
       "      <td>0.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.647354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.623440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.611860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.540972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.494840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.456080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.436291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.389779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.352889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.293495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.251743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.235206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.221126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.204005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.445455</td>\n",
       "      <td>0.445455</td>\n",
       "      <td>0.160380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.142867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.123123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.572727</td>\n",
       "      <td>0.102264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.096626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.079847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.065039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FalsePositiveRate  TruePositiveRate  Thresholds\n",
       "0            0.000000          0.000000    1.943997\n",
       "1            0.000000          0.000000    0.943997\n",
       "2            0.009091          0.009091    0.939609\n",
       "3            0.009091          0.009091    0.927748\n",
       "4            0.009091          0.009091    0.925138\n",
       "5            0.009091          0.009091    0.919399\n",
       "6            0.009091          0.009091    0.916405\n",
       "7            0.009091          0.009091    0.908148\n",
       "8            0.009091          0.009091    0.893059\n",
       "9            0.009091          0.009091    0.857308\n",
       "10           0.009091          0.009091    0.837453\n",
       "11           0.009091          0.009091    0.832171\n",
       "12           0.009091          0.009091    0.798673\n",
       "13           0.009091          0.009091    0.790673\n",
       "14           0.009091          0.009091    0.738398\n",
       "15           0.009091          0.009091    0.684879\n",
       "16           0.027273          0.027273    0.682558\n",
       "17           0.063636          0.063636    0.674200\n",
       "18           0.081818          0.081818    0.647354\n",
       "19           0.081818          0.081818    0.623440\n",
       "20           0.109091          0.109091    0.611860\n",
       "21           0.127273          0.127273    0.540972\n",
       "22           0.127273          0.127273    0.494840\n",
       "23           0.145455          0.145455    0.456080\n",
       "24           0.145455          0.145455    0.436291\n",
       "25           0.227273          0.227273    0.389779\n",
       "26           0.236364          0.236364    0.352889\n",
       "27           0.290909          0.290909    0.293495\n",
       "28           0.309091          0.309091    0.251743\n",
       "29           0.336364          0.336364    0.235206\n",
       "30           0.336364          0.336364    0.221126\n",
       "31           0.427273          0.427273    0.204005\n",
       "32           0.445455          0.445455    0.160380\n",
       "33           0.481818          0.481818    0.142867\n",
       "34           0.563636          0.563636    0.123123\n",
       "35           0.572727          0.572727    0.102264\n",
       "36           0.890909          0.890909    0.096626\n",
       "37           0.909091          0.909091    0.079847\n",
       "38           0.990909          0.990909    0.065039\n",
       "39           1.000000          1.000000    0.011007"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'FalsePositiveRate':fpr,'TruePositiveRate':fpr,'Thresholds':thresholds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorperating this:\n",
    "    New array == "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True,  True, False, False, False, False,\n",
       "        True,  True, False,  True, False,  True,  True, False,  True,\n",
       "       False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "       False, False,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True, False, False,\n",
       "        True,  True,  True, False,  True, False, False,  True,  True,\n",
       "        True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "        True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False,  True,\n",
       "        True,  True, False, False,  True,  True, False,  True, False,\n",
       "       False, False,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True, False,  True, False,  True, False,  True, False,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "        True,  True, False, False,  True,  True,  True, False,  True,\n",
       "       False,  True, False,  True,  True, False,  True,  True])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba > 0.20000947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VGX2wPHvIaGDCITeQqgJTSGCgIgIUhRUVBRlcXEDERBE0VVsiCzyAwRRlI6IImJbUHDZRdZdy6KIkQ4KhNBDSSAESCgp5/fHDGOIKRPIZDKZ83meeZh7587cc0Nyz7zvfe95RVUxxhhjAIp5OwBjjDGFhyUFY4wxLpYUjDHGuFhSMMYY42JJwRhjjIslBWOMMS6WFIwxxrhYUjA+SUT2icg5ETkrIkdFZJGIlMu0TQcR+Y+InBGRRBFZKSJhmba5RkTeEJEDzs+Kdi4HZbNfEZHHRWSbiCSJyCER+VREWnjyeI0pKJYUjC/ro6rlgOuA64HnLr0gIu2Br4AvgJpAfWAzsFZEQpzblAC+BpoBPYFrgA7ACaBtNvt8ExgFPA5UAhoDnwN35DV4EQnM63uM8TSxO5qNLxKRfcBgVf23c3kK0ExV73Aufw9sVdXhmd73TyBOVR8WkcHAq0ADVT3rxj4bAb8B7VV1fTbbfAN8oKoLnMuDnHHe5FxWYATwBBAIrAbOqurTGT7jC+BbVX1dRGoCbwE3A2eB6ao6w40fkTFXxFoKxueJSG2gFxDtXC6D4xv/p1ls/glwm/N5N+Bf7iQEp67AoewSQh7cDbQDwoAPgQdERABEpCLQHfhIRIoBK3G0cGo59/+EiPS4yv0bky1LCsaXfS4iZ4CDwHHgZef6Sjh+t49k8Z4jwKXrBZWz2SY7ed0+O/+nqidV9RzwPaBAJ+dr9wE/qmoscANQRVXHq+pFVY0B5gP98yEGY7JkScH4srtVtTxwC9CU30/2CUA6UCOL99QA4p3PT2SzTXbyun12Dl56oo7+24+AB52rHgKWOJ/XA2qKyKlLD+B5oFo+xGBMliwpGJ+nqt8Ci4CpzuUk4EegXxab34/j4jLAv4EeIlLWzV19DdQWkfActkkCymRYrp5VyJmWlwL3iUg9HN1Kf3euPwjsVdVrMzzKq+rtbsZrTJ5ZUjBFxRvAbSJynXN5DPBn5/DR8iJSUUQmAO2BV5zbLMZx4v27iDQVkWIiUllEnheRP5x4VXU3MAtYKiK3iEgJESklIv1FZIxzs03APSJSRkQaAhG5Ba6qG4E4YAGwWlVPOV9aD5wWkWdFpLSIBIhIcxG54Up+QMa4w5KCKRJUNQ54H3jJufw/oAdwD47rAPtxDFu9yXlyR1Uv4LjY/BuwBjiN40QcBPyUza4eB94GZgKngD1AXxwXhAGmAxeBY8B7/N4VlJulzlg+zHBMaUAfHENu9+Lo9loAVHDzM43JMxuSaowxxsVaCsYYY1wsKRhjjHGxpGCMMcbFkoIxxhgXSwrGGGNcLCkYY4xxsaRgjDHGxZKCMcYYF0sKxhhjXCwpGGOMcbGkYIwxxsWSgjHGGBdLCsYYY1wsKRhjjHGxpGCMMcbFkoIxxhgXSwrGGGNcAr0dQF4FBQVpcHCwt8Mwxhif8ssvv8SrapXctvO5pBAcHExUVJS3wzDGGJ8iIvvd2c66j4wxxrhYUjDGGONiScEYY4yLJQVjjDEulhSMMca4eCwpiMhCETkuItuyeV1EZIaIRIvIFhFp7alYjDHGuMeTLYVFQM8cXu8FNHI+IoHZHozFGGOMGzx2n4KqficiwTlschfwvqoqsE5ErhWRGqp6xFMxGWOML0hJS2d77Gk27E/gVPJFLqakkJyczL03NqZVnWs9um9v3rxWCziYYfmQc90fkoKIROJoTVC3bt0CCc4YYwpKYnIKGw4kELX/JFH7Eth86BTnU9IBEEDV8bxR7apFOilIFus0qw1VdR4wDyA8PDzLbYwxxheoKvtPJBO1P4FfnElg9/GzAAQUE5rVvIYH29YltEpJVi58kw/mv03Dhg1ZsGABndsHezw+byaFQ0CdDMu1gVgvxWKMMR5xMTWdbbGJ/LLP0RL4Zf8p4s9eAKB8qUDa1KvIXdfVpE29SrSqU4EyJQJJS0ujRYsW7Ny5k2eeeYZx48ZRunTpAonXm0lhBTBCRD4C2gGJdj3BGOPrEpIu8sv+BFdLYPOhRC6mOrp/6lYqw82NgmgTXJHwepVoVLUcxYr93mly4sQJSleqREBAAK+++ip16tQhPDy8QOP3WFIQkaXALUCQiBwCXgaKA6jqHGAVcDsQDSQDj3gqFmOM8QRVZW98kiMBOFsCe+KSACgeIDSrWYGHb6xHm3oVaRNckarlS2X7OUuWLGHUqFFMmjSJIUOG0Ldv34I8FBdPjj56MJfXFXjMU/s3xpgrcfp8Cvvik9gbn0RMnOPf2FPnSNPLL2eqwsGTyZxIughAhdLFaVOvIve0rk14vYq0qnMtpYoH5Lq/gwcPMnToUFatWsWNN95Ix44dPXJc7vK50tnGGHO1zqekceBksuukvzf+LPvik4mJT3L19wOIQK1rS1OnYhlKB/xxbMwtTaoSHlyR8HoVaVDl8q4gdyxdupRHH32UtLQ03njjDUaMGEFAQO6JxJMsKRhjiqS0dOVwwjli4s86T/y/Pw6fOkfGL/5B5UoSElSWrk2rUr9KWeoHlSUkqCx1KpVx69v+lapYsSLt2rVj3rx51K9f32P7yQtR9a0RnuHh4WqT7BhjwNEXH3fmAjGZTvp745M4cCKZi2nprm3Llwx0nfAvPUKCyhEcVIbypYoXSLypqalMnz6dixcv8sILL7iOQSRvLYwrISK/qGquV62tpWCMKfQSz6W4unn2xif//jwuiaSLaa7tSgQWI7hyGRpUKUu30GqEBJUl2JkAgsqVKJCTb3Y2b95MREQEv/zyC/fff78rGXgzpqxYUjDGFArnU9LYdyKJvXFJ7L30r/Nb/6WLuQDFBGpXLEP9oLKE16tESJWyBFd2nPhrXluagDz263vahQsXmDBhApMmTaJSpUp8+umn3HvvvYUuGVxiScEYU2BS09I5lHDuDyf9vfFJxCZe3s9ftXxJ6geVpXuzaq6TfkgVRz9/yUDvXozNi927dzN58mQeeughXn/9dSpXruztkHJkScEYk69UlWOnL2Q44Tsu9MbEJ3HwZDIpab+f+cuXCiSkSjna1q/kOPFXKevq8ilX0ndPT2fPnuWLL75gwIABNG/enN9++42QkBBvh+UW3/2pG2O86lTyxcu+6cfEO7797zuRRHKGfv6SgcWoH1SWJtXK06NZddfInvpBZalU1rv9/J6wZs0aIiMj2b9/P61btyY0NNRnEgJYUjDG5ODcRWc//2U3czm++Sckp7i2Cygm1KlYmuCgsrQLqeQ86ZejfpWy1LimVJ7H7/uihIQEnn76aRYuXEjjxo359ttvCQ0N9XZYeWZJwRg/l3Kpnz/+bIabuRyPI4nnL9u22jWOfv6ezWu4vu3Xr1KWOhXLUCLQf2f3TUtLo2PHjuzatYvnnnuOsWPHUqpU1iUtCjtLCsb4gfR05diZ8+yNS/rDmP6DJ5NJTf+9n79C6eLUDypL+5DKrpN+/SDHCJ+yPtzP7wnx8fFUchawmzhxInXr1qV1a9+eWdj+h40pQhKSLmY46V+6kzeZffFJnEv5vZ+/VPFiBFcuS2iN8tzeorqjq8fZ11+xbAkvHoFvUFUWL17ME088waRJk4iMjOTuu+/2dlj5wpKCMT4m+WLq79/0L43pdy6fytTPX7eSYzx/hwaVf7/AW6Us1cr7Rz+/J+zfv59HH32U1atX06FDB26++WZvh5SvLCkYr1uxOZajiee8HUahlZqujj5/Z3//0dOX9/PXqFCK+kFluaNFDddY/uDKjvH8xQP8t5/fEz744AOGDRuGqvLWW28xfPhwihUrWj9jSwrGqxKTU3h86UZvh1HoVSzj6Ofv2DCIkAx9/MFBZShTwv6MC0qVKlXo2LEjc+fOpV69et4OxyPst8l41aUa9S/cHspD7ep6OZrCqZgIpUv4zh28RUlKSgrTpk0jJSWFl156iR49etC9e/cid29FRpYUjEet33uSVVuPkJqenuXr51Mc60sEFrORLaZQ2bhxIxEREWzcuJH+/fsX2gJ2+c3+Co1HbD54imlrdvHdrjhKFw+gTA7fdKtdU5Km1csXYHTGZO/8+fOMHz+eKVOmEBQUxN///nfuueceb4dVYCwpmHy18+gZpn21k692HKNimeI816spD7cPtu4P4zOio6OZOnUqDz/8MNOmTaNixYreDqlAWVIwV+1Cahrf7oxj+cbD/Gv7UcqVCGT0bY15pGNwgU1eYszVOHv2LMuXL2fgwIE0b96cnTt3FpqZ0AqaJQVzRVLT0vlhzwlWbo7lX9uPcuZ8KpXKlmBY5wZE3hzCtWXsBijjG1avXk1kZCQHDx4kPDyc0NBQv00IYEnB5EF6uhK1P4GVm2NZtfUIJ5IuUr5kID2aV6dPq5p0aFDZxsUbn3HixAlGjx7N+++/T9OmTfn+++99soBdfrOkYHKkqmw9nMjKzbF8ueUIRxLPU6p4MbqFVqNPq5p0blzFoxObG+MJlwrYRUdH88ILL/Diiy/6bAG7/GZJwWRp17EzrNwcy8rNsew7kUzxAKFz4yqM6dWUbqHVbPio8UlxcXFUrlyZgIAAJk+eTL169bjuuuu8HVahYn/ZxmX/iSS+3HKEFZti2XnsDMUEOjQIYvgtDenRrDoVythFY+ObVJVFixYxevRoJk2axKOPPspdd93l7bAKJUsKBoD3f9zH2C+2AxBeryKv3NmM21vUoEr5kt4NzJirtG/fPiIjI1mzZg2dOnWiS5cu3g6pULOkYEi+mMr0NbtoV78Srz9wHbWuLe3tkIzJF4sXL2bYsGGICLNmzeLRRx8tcgXs8pslBcOHPx0gITmFZ3o2tYRgipRq1apx8803M2fOHOrWtdpa7rCk4OfOp6Qx77sYOjSoTJt6/nXnpil6UlJSmDJlCmlpaYwdO5bu3bvTvXt3b4flU6wd5ec+/eUQx89cYESXht4OxZirsmHDBm644QZefPFFdu7ciarm/ibzBx5NCiLSU0R2iki0iIzJ4vW6IvJfEdkoIltE5HZPxmMud+5iGnO+2UPrutfSvkFlb4djzBU5d+4cY8aMoW3bthw7dozly5ezZMmSIl/N1FM81n0kIgHATOA24BDws4isUNUdGTZ7EfhEVWeLSBiwCgj2VEwGUtLS+V90PCs3xfLVjmOcvZDKhL7N7Q/I+KyYmBhef/11Bg0axGuvveZ3BezymyevKbQFolU1BkBEPgLuAjImBQWucT6vAMR6MB6/lZaurN97khWbY/nntiOcSk7hmlKB3N6iOn2vr22tBONzTp8+zbJlyxg0aBDNmjVj9+7dRXYmtILmyaRQCziYYfkQ0C7TNuOAr0RkJFAW6ObBePyKqrLx4ClWbo7lH1uOcPzMBUoXD+C2sGrc2aomnRoHUTLQylMY37Nq1SqGDh3K4cOHadeuHaGhoZYQ8pEnk0JW/RGZr/w8CCxS1Wki0h5YLCLNVfWyabpEJBKIBGxYWQ5Uld+OnmGFszzFoYRzlAgoxi1NqnDndTW5tWlVm8/X+Kz4+HiefPJJPvjgA8LCwli7dq0VsPMAT54hDgF1MizX5o/dQxFATwBV/VFESgFBwPGMG6nqPGAeQHh4uA0pyCQm7iwrNx9h5ZZYoo+fJaCY0LFhEE90a0z3ZtW4xuY0MD7uUgG7mJgYxo4dy/PPP0/Jkna3vSd4Min8DDQSkfrAYaA/8FCmbQ4AXYFFIhIKlALiPBhTkXH41Dm+3BzLyi2xbDt8GhG4IbgSf7u7Obc3r07lcvYHY3zfsWPHqFKlCgEBAUydOpV69erRsmVLb4dVpHksKahqqoiMAFYDAcBCVd0uIuOBKFVdATwFzBeRJ3F0LQ1SG1ycrbgzF1i19QgrN8cStT8BgFa1K/DiHaHc0bIGNSrY3cimaFBVFi5cyFNPPcWkSZMYOnQoffr08XZYfsGjHcyqugrHMNOM68ZmeL4D6OjJGHxdYnIKq7cfZcXmWH7YE0+6QpNq5Xm6e2N6t6xJcFBZb4doTL6KiYlhyJAh/Oc//6Fz585062bjTwqSXXUspM5dTGP0J5v496/HSElT6lUuw/BbGtKnVU2aVC/v7fCM8Yj33nuP4cOHExAQwJw5cxgyZIgVsCtglhQKqZj4s/xz21F6t6zBkE4htKxdwW4wM0VezZo1ufXWW5k9eza1a9f2djh+yZJCIdenVU1a1bnW22EY4xEXL15k0qRJpKenM27cOG677TZuu+02b4fl16xdVgilpSs/xZz0dhjGeNTPP/9MmzZtePnll4mJibECdoWEtRQKEVVl9fZjvL5mJ7uOnaVp9fK0qm2tBFO0JCcnM3bsWKZPn06NGjVYsWKFjSwqRCwpFAKqyre74pj21S62Hk4kJKgsbz14PXe0qEGxYnYdwRQte/fu5a233mLIkCFMnjyZChUqeDskk4ElhULg1X/8yoL/7aV2xdK8dl9L+l5fi8AA69kzRUdiYiLLli3jkUceoVmzZkRHR1OnTp3c32gKnCWFQmDX8bM0rlaOL0d2okSgJQNTtPzjH//g0Ucf5ciRI7Rv356mTZtaQijE7AxUSJQpEWgJwRQpcXFxDBgwgN69e1OxYkV+/PFHmjZt6u2wTC6spWCMyXdpaWncdNNN7N27l1deeYUxY8ZQokQJb4dl3OBWUhCREkBdVY32cDzGGB929OhRqlatSkBAANOmTSM4OJjmzZt7OyyTB7n2V4jIHcBWYI1z+ToRWe7pwIqqPXFn2XTw1GWP0+dSvB2WMVclPT2duXPn0rhxY+bOnQtA7969LSH4IHdaCuNxzJj2XwBV3SQiDT0aVRG1dP0Bnlu2NcvXOtiUmMZHRUdHM2TIEL755htuvfVWevTo4e2QzFVwJymkqOqpTHV37NbDPNp17AzjVmynY8PKDL4p5A+vh9a4Jot3GVO4vfvuuwwfPpwSJUowf/58IiIirEaXj3MnKfwqIvcDxZwT5owC1nk2rKLlfEoajy/dSPlSgUx/4Dqqli/l7ZCMyRd169alR48ezJw5k1q1ank7HJMP3BkDOQJoA6QDy4DzOBKDcdP/rfqV346eYWq/VpYQjE+7cOEC48aNY+xYx7QoXbt25fPPP7eEUIS4kxR6qOqzqnq98zEG6OXpwIqKNTuO8d6P+xl8U31uaVLV2+EYc8V++ukn2rRpwyuvvMKBAwesgF0R5U5SeDGLdS/kdyBF0dHE8zzz2Waa1byGv/Zs4u1wjLkiSUlJjB49mvbt25OYmMiXX37JokWL7NpBEZXtNQUR6QH0BGqJyOsZXroGR1eSyUFauvLkx5s4n5LOjAevp2RggLdDMuaK7N+/n1mzZjF06FAmTZrENdfYoIiiLKcLzceBbTiuIWzPsP4MMMaTQRUFc77dw48xJ5hyX0saVCnn7XCMyZNTp07x2WefMXjwYMLCwoiOjraZ0PxEtklBVTcCG0VkiaqeL8CYfN6GAwm8vmYXvVvWoF8b+0MyvuWLL75g2LBhHD9+nJtuuommTZtaQvAj7lxTqCUiH4nIFhHZdenh8ch81OnzKYz6aCM1KpTi1b4trN/V+Izjx4/Tv39/7r77bqpUqcK6deusgJ0fcuc+hUXABGAqjlFHj2DXFLKkqry4fBuxp87zyaPtqVC6uLdDMsYtaWlpdOzYkQMHDjBhwgSeeeYZihe3319/5E5SKKOqq0VkqqruAV4Uke89HZgvWrX1KCs2x/J098a0qVfR2+EYk6vY2FiqV69OQEAAb775JsHBwYSFhXk7LONF7nQfXRBHH8geERkqIn0AG3CfhQ0HEihdPIBht1hpKFO4paenM3v2bJo2bcqcOXMAuP322y0hGLdaCk8C5YDHgVeBCsBfPBmULwsoJgTYvMqmENu1axdDhgzhu+++o1u3bvTqZfeimt/lmhRU9Sfn0zPAQAAR8euhCPvik3j8o43Enblw2frEcykE2IVlU4i98847jBgxglKlSrFw4UIGDRpkgyHMZXJMCiJyA1AL+J+qxotIM+BZ4FbALxPDoYRkBiz4ieSLqdwWVu0PrzerWcELURnjnuDgYHr16sXMmTOpUaOGt8MxhZBkV79ERP4PuBfYDNQHluMohDcZmK2qyQUVZEbh4eEaFRXljV1zNPE898/9kVPJF/lwyI00r2UJwBRuFy5c4G9/+xsAEyZM8HI0xptE5BdVDc9tu5xaCncBrVT1nIhUAmKdyzvzK0hfEnfmAg8tWMfJpIssjmhrCcEUej/88AMRERH89ttv/OUvf0FVravI5Cqn0UfnVfUcgKqeBH7z14SQkHSRge/8xJFT53n3kRu4vq4NNzWF19mzZxk1ahQ33XQTycnJ/Otf/+Kdd96xhGDcklNSCBGRZc7HciA4w/Iydz5cRHqKyE4RiRaRLOslicj9IrJDRLaLyIdXchCelHguhYELfyImPokFfw7nhuBK3g7JmBwdOHCAuXPn8thjj7Ft2zabHtPkSU7dR/dmWn47Lx8sIgHATOA24BDws4isUNUdGbZpBDwHdFTVBBEpVPc/nL2QyqB317Pz6BnmPRxOx4ZB3g7JmCwlJCTw6aefEhkZSVhYGDExMdSsWdPbYRkflFNBvK+v8rPbAtGqGgMgIh/huE6xI8M2Q4CZqprg3Ofxq9xnvjl3MY2/LPqZLYcSmTWgNV1sghxTSC1fvpzhw4cTFxdH586dadKkiSUEc8XcuaP5StUCDmZYPuRcl1FjoLGIrBWRdSLSM6sPEpFIEYkSkai4uDgPhfu78ylpDHk/iqh9J3njgevo0ay6x/dpTF4dPXqUfv36cc8991C9enXWr19PkyY2mZO5Ou7c0XylsrqqlXn8ayDQCLgFx30P34tIc1U9ddmbVOcB88AxJDX/Q/3dxdR0hi/ZwP+i45narxV9Wtk3LlP4pKWl0alTJw4ePMjEiRN5+umnrYCdyRduJwURKamqF3Lf0uUQUCfDcm0cw1ozb7NOVVOAvSKyE0eS+DkP+8k3qWnpPL50I//57TgT+7bgPpsLwRQyhw4dombNmgQEBDBjxgzq169v5a1Nvso1KYhIW+AdHDWP6opIK2Cwqo7M5a0/A41EpD5wGOgPPJRpm8+BB4FFIhKEozspJm+HkHd74s7y/a4/dkP9sOcEX+04xst9wnioXV1Ph2GM29LT05k5cybPPfcckydP5rHHHrOaRcYj3GkpzAB64ziBo6qbRaRLbm9S1VQRGQGsBgKAhaq6XUTGA1GqusL5WncR2QGkAX9V1RNXeCxum7p6J//cdvQP64sJjOnVlEc61vd0CMa47bfffmPw4MGsXbuWHj160Lt3b2+HZIowd5JCMVXdn+nGlzR3PlxVVwGrMq0bm+G5AqOdjwKTkqY0qVaejyJvvGx98cBilCvpycssxuTNggULGDFiBGXKlOG9995j4MCBdhOa8Sh3zoAHnV1I6rz3YCTg89NxBhQTKpYt4e0wjMlRgwYN6NOnD2+//TbVqv2xAKMx+c2dpDAMRxdSXeAY8G/nOmNMPjt//jzjx48HYOLEiXTp0oUuXXLtrTUm37iTFFJVtb/HIzHGz61du5aIiAh27tzJ4MGDrYCd8Qp3bl77WURWicifRaS8xyMyxs+cOXOGkSNH0qlTJy5cuMDq1auZP3++JQTjFbkmBVVtAEwA2gBbReRzEbGWgzH55NChQyxYsICRI0eydetWunfv7u2QjB9zq8yFqv6gqo8DrYHTwBKPRmVMEXfixAlmz54NQGhoKDExMbz55puUK1fOy5EZf5drUhCRciIyQERWAuuBOKCDxyMzpghSVT777DPCwsJ4/PHH2bnTMUWJTY1pCgt3WgrbgBuBKaraUFWfUtWfPByXMUXOkSNHuPfee+nXrx916tQhKirKCtiZQsed0Uchqpru8UiMKcIuFbA7fPgwU6ZM4cknnyQw0G6UNIVPtr+VIjJNVZ8C/i4if6hMqqr3eDQyY4qAgwcPUqtWLQICApg5cyb169encePG3g7LmGzl9FXlY+e/eZpxzRjjaBlcKmA3ZcoUHnvsMZsW0/iEnGZeW+98GqqqlyUGZ6G7q52ZzZgi6ddffyUiIoIff/yRXr160adPH2+HZIzb3LnQ/Jcs1kXkdyDGFAXz5s3juuuuY9euXSxevJh//OMf1K1rZdiN78jpmsIDOOZAqC8iyzK8VB44lfW7jPFvjRo1om/fvsyYMYOqVW1eb+N7crqmsB44gWPGtJkZ1p8BNnoyKGN8xblz5xg3bhwiwqRJk6yAnfF5OV1T2AvsxVEV1RiTyXfffcfgwYPZvXs3Q4cOtQJ2pkjI9pqCiHzr/DdBRE5meCSIyMmCC9GYwuX06dMMHz6czp07k5aWxtdff83s2bMtIZgiIafuo0tt4KCCCMQYXxEbG8uiRYsYPXo048ePp2zZst4OyZh8k21LIcNdzHWAAFVNA9oDjwL2V2D8Snx8PLNmzQKgadOm7N27l2nTpllCMEWOO0NSP8cxFWcD4H0gFPjQo1EZU0ioKh9//DFhYWE88cQT7NrlmInWpsY0RZU7SSFdVVOAe4A3VHUkUMuzYRnjfbGxsdx9993079+fevXq8csvv1iJClPkuTUdp4j0AwYCdzvXFfdcSMZ4X1paGjfffDOHDx9m6tSpjBo1ygrYGb/gzm/5X4DhOEpnx4hIfWCpZ8Myxjv2799P7dq1CQgIYNasWYSEhNCwYUNvh2VMgXFnOs5twONAlIg0BQ6q6qsej8yYApSWlsbrr79OaGioa0a07t27W0IwfifXloKIdAIWA4cBAaqLyEBVXevp4IwpCNu2bSMiIoL169fTu3dv7r777tzfZEwR5U730XTgdlXdASAioTiSRLgnAzOmIMyZM4fHH3+cChUq8OGHH9K/f3+7Cc34NXdGH5W4lBAAVPVXoITnQjLG81Qd80aFhobSr18/duzYwYMPPmgJwfg9d1oKG0RkLo7WAcAArCCe8VHJyckJcedrAAAVgklEQVSMHTuWgIAAJk+eTOfOnencubO3wzKm0HCnpTAU2AM8AzwLxOC4q9kYn/LNN9/QsmVLpk2bxtmzZ12tBWPM73JsKYhIC6ABsFxVpxRMSMbkr8TERJ555hnmzZtHgwYN+M9//mPlrY3JRk5VUp/HUeJiALBGRLKagS1HItJTRHaKSLSIjMlhu/tEREXELl6bfHfkyBE++OADnn76abZs2WIJwZgc5NRSGAC0VNUkEakCrAIWuvvBIhKAY3Ke24BDwM8isiLjRWvnduVx3AfxU16DNyY7cXFxfPTRR4wcOZKmTZuyb98+qlSp4u2wjCn0crqmcEFVkwBUNS6XbbPSFohW1RhVvQh8BNyVxXZ/A6YA5/P4+cb8gary4YcfEhoaylNPPeUqYGcJwRj35HSiDxGRZc7HcqBBhuVlObzvklrAwQzLh8hUSE9ErgfqqOqXeY7cmEwOHjxInz59GDBgAA0bNmTjxo1WwM6YPMqp++jeTMtv5/Gzsxrw7RruISLFcNwYNyjXDxKJBCIB6tatm8cwjD9ITU3llltu4ejRo0yfPp2RI0cSEBDg7bCM8Tk5zdH89VV+9iEcE/RcUhuIzbBcHmgOfOO8Yag6sEJE7lTVqEyxzAPmAYSHh9s4QuOyb98+6tSpQ2BgIHPnziUkJISQkBBvh2WMz8rrdYK8+BloJCL1RaQE0B9YcelFVU1U1SBVDVbVYGAd8IeEYExWUlNTmTp1KqGhoa4Z0bp162YJwZir5LEC8aqaKiIjgNVAALBQVbeLyHggSlVX5PwJxmRty5YtREREEBUVxV133cW992bu6TTGXCm3k4KIlFTVC3n5cFVdhWMoa8Z1Y7PZ9pa8fLbxT7NmzWLUqFFUrFiRjz/+mH79+lm9ImPyUa7dRyLSVkS2Arudy61E5C2PR2ZMBpdKUjRv3pz+/fuzY8cO7r//fksIxuQzd1oKM4DeOO5uRlU3i4jdEmoKRFJSEi+++CKBgYG89tpr3Hzzzdx8883eDsuYIsudC83FVHV/pnVpngjGmIy+/vprWrRowRtvvMGFCxesgJ0xBcCdpHBQRNoCKiIBIvIEsMvDcRk/durUKQYPHky3bt0IDAzku+++Y8aMGdZVZEwBcCcpDANGA3WBY8CNznXGeMSxY8f46KOPePbZZ9m8eTOdOnXydkjG+I1crymo6nEc9xgY4zGXEsGoUaNo0qQJ+/btIygoyNthGeN3ck0KIjKfDOUpLlHVSI9EZPyKqrJkyRJGjRrF2bNnuf3222nUqJElBGO8xJ3uo38DXzsfa4GqQJ7uVzAmKwcOHOCOO+5g4MCBNGnShE2bNtGoUSNvh2WMX3On++jjjMsishhY47GIjF+4VMDu+PHjzJgxg+HDh1sBO2MKgSspc1EfqJffgRj/EBMTQ7169QgMDGT+/Pk0aNCA4OBgb4dljHFy547mBBE56XycwtFKeN7zoZmiJDU1lcmTJxMWFsbMmTMB6Nq1qyUEYwqZHFsK4hgY3go47FyVrnYHkcmjTZs2ERERwYYNG+jbty/9+vXzdkjGmGzk2FJwJoDlqprmfFhCMHny9ttvc8MNN3D48GE+++wzli1bRo0aNbwdljEmG+6MPlovIq09HokpUi59f2jZsiUDBgxgx44dVuLaGB+QbfeRiASqaipwEzBERPYASTim2VRVtURh/uDs2bO88MILFC9enKlTp1oBO2N8TE7XFNYDrYG7CygW4+O++uorIiMjOXDgACNHjkRVrV6RMT4mp6QgAKq6p4BiMT4qISGB0aNHs2jRIpo0acJ3333HTTfd5O2wjDFXIKekUEVERmf3oqq+7oF4jA86fvw4n332Gc899xxjx46lVKlS3g7JGHOFckoKAUA5nC0GYzI6evQoS5cu5cknn3QVsKtcubK3wzLGXKWcksIRVR1fYJEYn6CqvP/++zz55JMkJyfTu3dvGjVqZAnBmCIipyGp1kIwl9m3bx89e/Zk0KBBhIWFWQE7Y4qgnFoKXQssClPopaam0qVLF+Lj45k5cyZDhw6lWDF3bnMxxviSbJOCqp4syEBM4RQdHU39+vUJDAxk4cKFhISEUK+e1UM0pqiyr3omSykpKUycOJFmzZq5Cth16dLFEoIxRdyVlM42RdyGDRuIiIhg06ZN9OvXjwceeMDbIRljCoi1FMxlZsyYQdu2bTl69CjLli3jk08+oVq1at4OyxhTQCwpGOD3AnbXX389Dz/8MDt27KBv375ejsoYU9Cs+8jPnTlzhueee46SJUsybdo0OnXqRKdOnbwdljHGS6yl4Mf+9a9/0bx5c2bNmoWqYtNlGGMsKfihEydO8Oc//5levXpRtmxZ1q5dy+uvv24VTY0xlhT80YkTJ1i+fDkvvfQSGzdupH379t4OyRhTSHg0KYhITxHZKSLRIjImi9dHi8gOEdkiIl+LiA2C95AjR44wdepUVJXGjRuzf/9+xo8fT8mSJb0dmjGmEPFYUhCRAGAm0AsIAx4UkbBMm20EwlW1JfAZMMVT8fgrVWXhwoWEhoby0ksvER0dDUDFihW9HJkxpjDyZEuhLRCtqjGqehH4CLgr4waq+l9VTXYurgNqezAev7N37166d+9OREQErVq1YvPmzVbAzhiTI08OSa0FHMywfAhol8P2EcA/s3pBRCKBSIC6devmV3xFWmpqKrfeeisnTpxg9uzZREZGWgE7Y0yuPJkUshrKkuWYRxH5ExAOdM7qdVWdB8wDCA8Pt3GTOdi9ezchISEEBgby7rvv0qBBA+rUqePtsIwxPsKTXx0PARnPRrWB2MwbiUg34AXgTlW94MF4irSUlBQmTJhA8+bNefvttwG45ZZbLCEYY/LEky2Fn4FGIlIfOAz0Bx7KuIGIXA/MBXqq6nEPxlKkRUVFERERwZYtW+jfvz8PPvigt0Myxvgoj7UUVDUVGAGsBn4FPlHV7SIyXkTudG72Go55oD8VkU0issJT8RRVb775Ju3atSM+Pp4vvviCpUuXUrVqVW+HZYzxUR6tfaSqq4BVmdaNzfC8myf3X5SpKiJCeHg4ERERTJkyhWuvvdbbYRljfJwVxPMxp0+f5tlnn6VUqVJMnz6djh070rFjR2+HZYwpImyMog9ZtWoVzZo1Y968eQQGBloBO2NMvrOk4APi4+P505/+xB133EGFChX44YcfeO2116yAnTEm31lS8AEJCQmsXLmSl19+mQ0bNtCuXU73ABpjzJWzawqF1OHDh1myZAl//etfadSoEfv377cLycYYj7OWQiGjqsyfP5+wsDDGjRvHnj17ACwhGGMKhCWFQmTPnj107dqVyMhIWrduzZYtW2jYsKG3wzLG+BHrPiokUlNT6dq1KydPnmTu3LkMHjzYCtgZYwqcJQUv27lzJw0aNCAwMJD33nuPBg0aULu2VRA3xniHfRX1kosXL/LKK6/QokULZs6cCUDnzp0tIRhjvMpaCl6wfv16IiIi2LZtGw899BADBgzwdkjGGANYS6HAvfHGG7Rv395178GSJUsICgrydljGGANYUigwl0pStG3bliFDhrB9+3Z69+7t5aiMMeZy1n3kYYmJiTzzzDOULl2aN954gw4dOtChQwdvh2WMMVmyloIHrVy5krCwMBYsWEDJkiWtgJ0xptCzpOABcXFxPPTQQ9x5551UrlyZdevWMXnyZCtgZ4wp9CwpeEBiYiKrVq3ilVdeISoqihtuuMHbIRljjFvsmkI+OXjwIB988AFjxoyhYcOG7N+/nwoVKng7LGOMyRNrKVyl9PR05syZQ7NmzZgwYYKrgJ0lBGOML7KkcBV2797NrbfeyrBhw2jbti1bt261AnbGGJ9m3UdXKDU1ldtuu41Tp07xzjvv8Mgjj9iFZGOMz7OkkEe//vorjRo1IjAwkMWLF9OgQQNq1qzp7bCMMSZfWPeRmy5cuMDLL79My5YtefvttwHo1KmTJQRjTJFiLQU3rFu3joiICHbs2MHAgQMZOHCgt0MyxhiPsJZCLqZNm0aHDh04c+YMq1at4v3336dy5creDssYYzzCkkI20tPTAWjfvj1Dhw5l27Zt9OrVy8tRGWOMZ1n3USanTp3iqaeeokyZMrz11ltWwM4Y41f8sqWQXWG6zz//nLCwMN577z3Kly9vBeyMMX7H75LCV9uP8s2uOBpULedad/z4ce6//3769u1LtWrVWL9+PRMnTrT7DowxfsevksI3O48z4sONtKhVgf+7p4Vr/enTp1mzZg2vvvoq69evp3Xr1l6M0hhjvMdvrilsO5zIo4t/oVG1crz3l7acPBbLm4sX8/zzz9OwYUMOHDhA+fLlvR2mMcZ4lUdbCiLSU0R2iki0iIzJ4vWSIvKx8/WfRCTYU7GsjY7nQmo68we2Ycm782nWrBkTJ050FbCzhGCMMR5MCiISAMwEegFhwIMiEpZpswggQVUbAtOByZ6K55L7+/bhscceo3379mzfvt0K2BljTAaebCm0BaJVNUZVLwIfAXdl2uYu4D3n88+AruKhq7uX7jvYvn077777LqtXryY4ONgTuzLGGJ/lyWsKtYCDGZYPAe2y20ZVU0UkEagMxGfcSEQigUiAunXrXlEwDaqWp22NQKZs+IXgOrWu6DOMMaao82RSyOobf+aB/+5sg6rOA+YBhIeHX9HNA92bVad7s+pX8lZjjPEbnuw+OgTUybBcG4jNbhsRCQQqACc9GJMxxpgceDIp/Aw0EpH6IlIC6A+syLTNCuDPzuf3Af9Ru43YGGO8xmPdR85rBCOA1UAAsFBVt4vIeCBKVVcA7wCLRSQaRwuhv6fiMcYYkzuP3rymqquAVZnWjc3w/DzQz5MxGGOMcZ9flbkwxhiTM0sKxhhjXCwpGGOMcbGkYIwxxkV8bQSoiMQB+6/w7UFkulvaD9gx+wc7Zv9wNcdcT1Wr5LaRzyWFqyEiUaoa7u04CpIds3+wY/YPBXHM1n1kjDHGxZKCMcYYF39LCvO8HYAX2DH7Bztm/+DxY/arawrGGGNy5m8tBWOMMTkokkmhMM0NXVDcOObRIrJDRLaIyNciUs8bcean3I45w3b3iYiKiM+PVHHnmEXkfuf/9XYR+bCgY8xvbvxu1xWR/4rIRufv9+3eiDO/iMhCETkuItuyeV1EZIbz57FFRFrnawCqWqQeOCqy7gFCgBLAZiAs0zbDgTnO5/2Bj70ddwEccxegjPP5MH84Zud25YHvgHVAuLfjLoD/50bARqCic7mqt+MugGOeBwxzPg8D9nk77qs85puB1sC2bF6/HfgnjknKbgR+ys/9F8WWQqGaG7qA5HrMqvpfVU12Lq7DMemRL3Pn/xngb8AU4HxBBuch7hzzEGCmqiYAqOrxAo4xv7lzzApc43xegT9O5uVTVPU7cp5s7C7gfXVYB1wrIjXya/9FMSlkNTd05kmZL5sbGrg0N7SvcueYM4rA8U3Dl+V6zCJyPVBHVb8syMA8yJ3/58ZAYxFZKyLrRKRngUXnGe4c8zjgTyJyCEep/pEFE5rX5PXvPU88Op+Cl+Tb3NA+xO3jEZE/AeFAZ49G5Hk5HrOIFAOmA4MKKqAC4M7/cyCOLqRbcLQGvxeR5qp6ysOxeYo7x/wgsEhVp4lIexwTdzVX1XTPh+cVHj1/FcWWgj/ODe3OMSMi3YAXgDtV9UIBxeYpuR1zeaA58I2I7MPR97rCxy82u/u7/YWqpqjqXmAnjiThq9w55gjgEwBV/REohaNGUFHl1t/7lSqKScEf54bO9ZidXSlzcSQEX+9nhlyOWVUTVTVIVYNVNRjHdZQ7VTXKO+HmC3d+tz/HMagAEQnC0Z0UU6BR5i93jvkA0BVAREJxJIW4Ao2yYK0AHnaOQroRSFTVI/n14UWu+0j9cG5oN4/5NaAc8KnzmvoBVb3Ta0FfJTePuUhx85hXA91FZAeQBvxVVU94L+qr4+YxPwXMF5EncXSjDPLlL3kishRH91+Q8zrJy0BxAFWdg+O6ye1ANJAMPJKv+/fhn50xxph8VhS7j4wxxlwhSwrGGGNcLCkYY4xxsaRgjDHGxZKCMcYYF0sKptARkTQR2ZThEZzDtsHZVZPM4z6/cVbi3OwsEdHkCj5jqIg87Hw+SERqZnhtgYiE5XOcP4vIdW685wkRKXO1+zb+wZKCKYzOqep1GR77Cmi/A1S1FY5iia/l9c2qOkdV33cuDgJqZnhtsKruyJcof49zFu7F+QRgScG4xZKC8QnOFsH3IrLB+eiQxTbNRGS9s3WxRUQaOdf/KcP6uSISkMvuvgMaOt/b1Vmnf6uzzn1J5/pJ8vv8FFOd68aJyNMich+O+lJLnPss7fyGHy4iw0RkSoaYB4nIW1cY549kKIQmIrNFJEoc8yi84lz3OI7k9F8R+a9zXXcR+dH5c/xURMrlsh/jRywpmMKodIauo+XOdceB21S1NfAAMCOL9w0F3lTV63CclA85yx48AHR0rk8DBuSy/z7AVhEpBSwCHlDVFjgqAAwTkUpAX6CZqrYEJmR8s6p+BkTh+EZ/naqey/DyZ8A9GZYfAD6+wjh74ihrcckLqhoOtAQ6i0hLVZ2Boy5OF1Xt4ix98SLQzfmzjAJG57If40eKXJkLUyScc54YMyoOvO3sQ0/DUdMnsx+BF0SkNrBMVXeLSFegDfCzs7xHaRwJJitLROQcsA9H+eUmwF5V3eV8/T3gMeBtHPMzLBCRfwBul+ZW1TgRiXHWrNnt3Mda5+fmJc6yOMo+ZJx1634RicTxd10Dx4QzWzK990bn+rXO/ZTA8XMzBrCkYHzHk8AxoBWOFu4fJs1R1Q9F5CfgDmC1iAzGUWb4PVV9zo19DMhYME9Espxjw1mPpy2OImz9gRHArXk4lo+B+4HfgOWqquI4Q7sdJ44ZyCYBM4F7RKQ+8DRwg6omiMgiHIXhMhNgjao+mId4jR+x7iPjKyoAR5w18gfi+JZ8GREJAWKcXSYrcHSjfA3cJyJVndtUEvfnp/4NCBaRhs7lgcC3zj74Cqq6CsdF3KxGAJ3BUb47K8uAu3HMA/Cxc12e4lTVFBzdQDc6u56uAZKARBGpBvTKJpZ1QMdLxyQiZUQkq1aX8VOWFIyvmAX8WUTW4eg6SspimweAbSKyCWiKY8rCHThOnl+JyBZgDY6ulVyp6nkcFSg/FZGtQDowB8cJ9kvn532LoxWT2SJgzqULzZk+NwHYAdRT1fXOdXmO03mtYhrwtKpuxjE383ZgIY4uqUvmAf8Ukf+qahyOkVFLnftZh+NnZQxgVVKNMcZkYC0FY4wxLpYUjDHGuFhSMMYY42JJwRhjjIslBWOMMS6WFIwxxrhYUjDGGONiScEYY4zL/wOQJEek5/VV4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "fig.suptitle('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8655467720685113\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred_proba)) # closer to one the better the prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_importances = fitted_models['gb'].best_estimator_.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title_Mr         0.412447\n",
       "Gender           0.255681\n",
       "Pclass_3         0.113548\n",
       "Pclass_1         0.064344\n",
       "FamilySize_6     0.033101\n",
       "Title_Other      0.027963\n",
       "FamilySize_5     0.025589\n",
       "FamilySize_8     0.015022\n",
       "Title_Master     0.013030\n",
       "Embarked_S       0.011486\n",
       "AgeBand_4        0.009929\n",
       "FamilySize_11    0.007955\n",
       "Title_Mrs        0.006287\n",
       "FamilySize_7     0.001986\n",
       "FamilySize_4     0.001631\n",
       "Alone            0.000000\n",
       "Embarked_C       0.000000\n",
       "Pclass_2         0.000000\n",
       "FamilySize_1     0.000000\n",
       "FamilySize_2     0.000000\n",
       "FamilySize_3     0.000000\n",
       "AgeBand_2        0.000000\n",
       "AgeBand_3        0.000000\n",
       "Title_Miss       0.000000\n",
       "AgeBand_1        0.000000\n",
       "FareCat_0        0.000000\n",
       "Embarked_Q       0.000000\n",
       "FareCat_2        0.000000\n",
       "FareCat_3        0.000000\n",
       "AgeBand_0        0.000000\n",
       "FareCat_1        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(index=col_names, data=col_importances).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
