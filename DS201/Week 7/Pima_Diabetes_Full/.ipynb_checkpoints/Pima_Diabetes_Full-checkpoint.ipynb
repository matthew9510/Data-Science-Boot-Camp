{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:SteelBlue\">Lesson:</span> Building an ML Pipeline</h1>\n",
    "<hr>\n",
    "We've talked about the process of training a model already which is a failry straight forward process when were talking about a single model, with predefined HyperParameters.\n",
    "\n",
    "However, in most real life situations we DO NOT know what models may be the best suited for the task at hand, let alone the appropriate hyperparameters for each model. \n",
    "\n",
    "**The Solution?**\n",
    "\n",
    "We will write a series of loops that use *Cross-Validation* to \"test\" each model, including every combination of relevant hyperparameters â€”for each model, in order to discern which configuration is the most effective.\n",
    "\n",
    "**Relevant topics for this section on Building Pipelines:**\n",
    "1. Dictionaries\n",
    "2. Looping\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PyData Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for DataFrames\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns',None)\n",
    "pd.set_option('max_rows', None)\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Pickle for saving model files\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SKLearn Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logistic Regression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import RandomForestClassifier and GradientBoostingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries to make Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import make_pipeline from sklearn.pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# import StandardScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import GridSearchCV from sklearn.model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import roc_curve and auc from sklearn.metrics\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/pima_diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into `X` and `y` sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Outcome'], axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shape` of `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `shape` of `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split `X` and `y` into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to split both the `X` and `y` datasets into Train and Test sets. This will result in 4 datasets total.**\n",
    "\n",
    "```(X_train, X_test, y_train, y_test)```\n",
    "\n",
    "> **`X`:** `X_train` and `X_test`\n",
    "\n",
    "> **`y`:** `y_train` and `y_test`\n",
    "\n",
    "The **Train Set** is the set that we will operform further splits on, during the cross-validation step. The motivation for this is to find the best combination of model and hyperparameters, which we can only achieve by running performance metrics on every possible combination of Model and Hyperparameters.\n",
    "\n",
    "The **Test Set** will remain untouched until after the cross-validation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_test_split()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will pass in the following values to `train_test_split`\n",
    "```python \n",
    "X\n",
    "y\n",
    "test_size = 0.2, \n",
    "stratify = df['Outcome'], \n",
    "random_state = 123\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify = df['Outcome'], \n",
    "    random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `print` length of `X_train` and `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 614\n",
      "X_test: 154\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", len(X_train)) \n",
    "print(\"X_test:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `print` length of `y_train` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: 614\n",
      "y_test: 154\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train:\", len(y_train)) \n",
    "print(\"y_test:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both **Train** sets, **X_train and y_train**, should have the **same number of rows**\n",
    "\n",
    "Both **Test** sets, **X_test and y_test**, should also have the **same number of rows**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Pipeline Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline dictionary can contain as many models as your heart's content. We use this approach to automate the process of fitting a model, predicting labels, and finally testing model accuracy.\n",
    "\n",
    "This will all be done with the SKlearn model_selection function **GridSearchCV()** which expects at least two arguments a **Pipeline** dictionary and a **Hyperparameters** dictionary, with matching keys!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Standard_Scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7c44621cf89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pipeline_dict = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m\"l1\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandard_Scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"l2\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandard_Scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"rf\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandard_Scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"gb\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandard_Scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Standard_Scaler' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline_dict = {\n",
    "    \"l1\" : make_pipeline(StandardScaler(), LogisticRegression(penalty=\"l1\", random_state = 123)),\n",
    "    \"l2\" : make_pipeline(StandardScaler(), LogisticRegression(penalty=\"l2\", random_state = 123)),\n",
    "    \"rf\" : make_pipeline(StandardScaler(), RandomForestClassifier(random_state = 123)),\n",
    "    \"gb\" : make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state = 123)),\n",
    "    \"kn\" : make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 1</span> - Dictionary Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through pipeline dict to print out the type of object that is associated with every model \"key.\"\n",
    "\n",
    "Remember dictionaries are set up like:\n",
    "```python \n",
    "some_dict = {\n",
    "    key1 : val1\n",
    "    key2 : val2\n",
    "}```\n",
    "\n",
    "\n",
    "**Hint:** I want you to **print every key** and the **type of every matching value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do work here so you don't erase the answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: <class 'sklearn.pipeline.Pipeline'>\n",
      "l2: <class 'sklearn.pipeline.Pipeline'>\n",
      "rf: <class 'sklearn.pipeline.Pipeline'>\n",
      "gb: <class 'sklearn.pipeline.Pipeline'>\n",
      "kn: <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for key, val in pipeline_dict.items():\n",
    "    print(key + \":\", type(val))\n",
    "    \n",
    "# Your code should output this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a Hyperparameters Nested-Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following describes the goal for this section, however we will begin with some exercises to help understand the concept of a nested dictionary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Final Hyperparameter Dictionary: `hp_dict`**\n",
    "\n",
    "> Every `key` in `hp_dict` will match the keys from `pipeline_dict`.\n",
    "\n",
    "> Every `value` in `hp_dict` will be a dictionary.\n",
    "\n",
    "**Nested Dictionaries inside `hp_dict`**\n",
    "\n",
    "> Every `key` in each nested `dict` will be a different hyperparameter that needs tuning.\n",
    "\n",
    "> Every `value` will hold a range of values that each particular hyperparameter can take on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of an `hp_dict` with values for 2 different models**\n",
    "\n",
    "*Notice that the `values` of `hp_dict` are surrounded by `{}`, this means that they are themselves dictionaries!*\n",
    "```python \n",
    "hp_dict = {\n",
    "    'kn':{\"kneighborsclassifier__n_neighbors\" : np.arange(1,11)}\n",
    "    'l1':{\"logisticregression__C\" : np.linspace(1e-4, 1e4, 10)}\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "\n",
    "## <span style=\"color:RoyalBlue\">Exercise 2</span> - Performing Action during Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop through `pipeline_dict` to print out the `type` of object that is associated with the `get_params()` method, for every model \"key.\"**\n",
    "\n",
    "**Remember:** Dictionaries in Python are set up like this:\n",
    "```python \n",
    "some_dict = {\n",
    "    key1 : val1\n",
    "    key2 : val2\n",
    "}```\n",
    "\n",
    "\n",
    "**Hint:** I want you to **`print` every `key`** and the **`type` of object that results from calling the `get_params()` method on every matching `value`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 <class 'dict'>\n",
      "l2 <class 'dict'>\n",
      "rf <class 'dict'>\n",
      "gb <class 'dict'>\n",
      "kn <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for key, val in pipeline_dict.items():\n",
    "    print(key, type(val.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What type of object does get_params() return? \n",
    "What could we do to said object?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 3</span> - Nested Dictionary Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since `get_params()` results in a `dict` object we can use `.items()` to loop through every `key` `value` pair inside of each parameter `dict`!**\n",
    "\n",
    "There is nothing stopping us from nesting a second for loop from inside a for loop!\n",
    "\n",
    "This is one of the harder concepts to understand at first, but once you get it, you'll realize how straightforward the process really is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory None\n",
      "steps [('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))]\n",
      "logisticregression LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "logisticregression__C 1.0\n",
      "logisticregression__class_weight None\n",
      "logisticregression__dual False\n",
      "logisticregression__fit_intercept True\n",
      "logisticregression__intercept_scaling 1\n",
      "logisticregression__max_iter 100\n",
      "logisticregression__multi_class warn\n",
      "logisticregression__n_jobs None\n",
      "logisticregression__penalty l1\n",
      "logisticregression__random_state 123\n",
      "logisticregression__solver warn\n",
      "logisticregression__tol 0.0001\n",
      "logisticregression__verbose 0\n",
      "logisticregression__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))]\n",
      "logisticregression LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "logisticregression__C 1.0\n",
      "logisticregression__class_weight None\n",
      "logisticregression__dual False\n",
      "logisticregression__fit_intercept True\n",
      "logisticregression__intercept_scaling 1\n",
      "logisticregression__max_iter 100\n",
      "logisticregression__multi_class warn\n",
      "logisticregression__n_jobs None\n",
      "logisticregression__penalty l2\n",
      "logisticregression__random_state 123\n",
      "logisticregression__solver warn\n",
      "logisticregression__tol 0.0001\n",
      "logisticregression__verbose 0\n",
      "logisticregression__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False))]\n",
      "randomforestclassifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
      "randomforestclassifier__bootstrap True\n",
      "randomforestclassifier__class_weight None\n",
      "randomforestclassifier__criterion gini\n",
      "randomforestclassifier__max_depth None\n",
      "randomforestclassifier__max_features auto\n",
      "randomforestclassifier__max_leaf_nodes None\n",
      "randomforestclassifier__min_impurity_decrease 0.0\n",
      "randomforestclassifier__min_impurity_split None\n",
      "randomforestclassifier__min_samples_leaf 1\n",
      "randomforestclassifier__min_samples_split 2\n",
      "randomforestclassifier__min_weight_fraction_leaf 0.0\n",
      "randomforestclassifier__n_estimators warn\n",
      "randomforestclassifier__n_jobs None\n",
      "randomforestclassifier__oob_score False\n",
      "randomforestclassifier__random_state 123\n",
      "randomforestclassifier__verbose 0\n",
      "randomforestclassifier__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('gradientboostingclassifier', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=123,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False))]\n",
      "gradientboostingclassifier GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=123,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "gradientboostingclassifier__criterion friedman_mse\n",
      "gradientboostingclassifier__init None\n",
      "gradientboostingclassifier__learning_rate 0.1\n",
      "gradientboostingclassifier__loss deviance\n",
      "gradientboostingclassifier__max_depth 3\n",
      "gradientboostingclassifier__max_features None\n",
      "gradientboostingclassifier__max_leaf_nodes None\n",
      "gradientboostingclassifier__min_impurity_decrease 0.0\n",
      "gradientboostingclassifier__min_impurity_split None\n",
      "gradientboostingclassifier__min_samples_leaf 1\n",
      "gradientboostingclassifier__min_samples_split 2\n",
      "gradientboostingclassifier__min_weight_fraction_leaf 0.0\n",
      "gradientboostingclassifier__n_estimators 100\n",
      "gradientboostingclassifier__n_iter_no_change None\n",
      "gradientboostingclassifier__presort auto\n",
      "gradientboostingclassifier__random_state 123\n",
      "gradientboostingclassifier__subsample 1.0\n",
      "gradientboostingclassifier__tol 0.0001\n",
      "gradientboostingclassifier__validation_fraction 0.1\n",
      "gradientboostingclassifier__verbose 0\n",
      "gradientboostingclassifier__warm_start False\n",
      "--------------------------------------------------\n",
      "memory None\n",
      "steps [('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform'))]\n",
      "kneighborsclassifier KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "kneighborsclassifier__algorithm auto\n",
      "kneighborsclassifier__leaf_size 30\n",
      "kneighborsclassifier__metric minkowski\n",
      "kneighborsclassifier__metric_params None\n",
      "kneighborsclassifier__n_jobs None\n",
      "kneighborsclassifier__n_neighbors 5\n",
      "kneighborsclassifier__p 2\n",
      "kneighborsclassifier__weights uniform\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key, val in pipeline_dict.items():\n",
    "    for k, v in val.get_params().items():\n",
    "        print(k, v)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 4</span> - Making individual HyperParameter Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for L1 aka \"LASSO\" Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will to provide a range of values for the `logisticregression__C` hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be `10` *equally spaced values* between \n",
    "> `1e-4` or 0.0001 and `1e4` or 10,000\n",
    "\n",
    "**Hint**: What numpy *generator* function allows us to create a range of **equally spaced values**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(1e-4, 1e4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_hyperparameters = { \n",
    "    \"logisticregression__C\" : np.linspace(1e-4, 1e4, 10) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for L2 aka \"Ridge\" Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(1e-4, 1e4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_hyperparameters = { \n",
    "    \"logisticregression__C\" : np.linspace(1e-4, 1e4, 10) \n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyperparameters = { \n",
    "        \"randomforestclassifier__n_estimators\" : [10, 100, 200], \n",
    "        \"randomforestclassifier__max_features\" : [\"auto\", \"sqrt\",\"log2\",None]  \n",
    "}     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_hyperparameters = {\n",
    "        \"gradientboostingclassifier__n_estimators\" : [10, 100, 200],\n",
    "        \"gradientboostingclassifier__learning_rate\" : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        \"gradientboostingclassifier__max_depth\" : [1, 3, 5, 7, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_hyperparameters = { \"kneighborsclassifier__n_neighbors\" : \n",
    "                      np.arange(1,11)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5a</span> - Assemble `hp_dict`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    'l1' : l1_hyperparameters,\n",
    "    'l2' : l2_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters,\n",
    "    'kn' : kn_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5b</span> - Loop throu `hp_dict` to verify work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a for loop that prints out each `key` and `value` in `hp_dict`, no need to make it look fancy like me, can be done in 3 lines of code. My example took 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both a `Pipeline_dict` and a `hp_dict` we can build the loop that will handle cross-validation for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 6</span> - Write a loop that uses `GridSearchCV()` to fit models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb has been fitted\n",
      "kn has been fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipeline_dict.items():\n",
    "    \n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hp_dict[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate metrics\n",
    "\n",
    "Finally, it's time to evaluate our models and pick the best one.\n",
    "\n",
    "<br>\n",
    "\n",
    "**First, display the <code style=\"color:steelblue\">best\\_score_</code> attribute for each fitted model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 7</span> - Access `best_score_` attribute for each cross-validation object in `fitted_models`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint: this is what it looks like to access the `best_score_` attribute for a single member of `fitted_models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7736156351791531"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['l1'].best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your for-loop here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 0.7736156351791531\n",
      "l2 0.7736156351791531\n",
      "rf 0.757328990228013\n",
      "gb 0.7638436482084691\n",
      "kn 0.737785016286645\n"
     ]
    }
   ],
   "source": [
    "for model_name, cv_obj in fitted_models.items():\n",
    "    print(model_name, cv_obj.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fitted_models['gb'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89 11]\n",
      " [27 27]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82       100\n",
      "           1       0.71      0.50      0.59        54\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       154\n",
      "   macro avg       0.74      0.70      0.71       154\n",
      "weighted avg       0.75      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC_Curve and Area_Under_ROC_Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = fitted_models['gb'].predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get False Positve / True Positive Rates and Matching Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>Thresholds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.935744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.935744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.836626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.826795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.790801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.749971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.745612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.744067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.684480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.604073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.590341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.571577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.557936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.551288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.546262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.523513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.510586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.482592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.481669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.480862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.456253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.437514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.423958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.412012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.408381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.392119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.391960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.379542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.376529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.356879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.331725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.327157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.320091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.309702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.301995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.277834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.275861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.246284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.224376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.223363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.217471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.209992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.203277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.198521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.183946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.174233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.165633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.164325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.150885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.144414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.123478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.119638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.118164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.111007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.110643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.106063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.099999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.098303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.060988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.060315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.025650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FPR   TPR  Thresholds\n",
       "0   0.00  0.00    1.935744\n",
       "1   0.00  0.00    0.935744\n",
       "2   0.00  0.00    0.836626\n",
       "3   0.00  0.00    0.826795\n",
       "4   0.00  0.00    0.790801\n",
       "5   0.02  0.02    0.749971\n",
       "6   0.02  0.02    0.745612\n",
       "7   0.03  0.03    0.744067\n",
       "8   0.03  0.03    0.684480\n",
       "9   0.05  0.05    0.604073\n",
       "10  0.06  0.06    0.590341\n",
       "11  0.06  0.06    0.571577\n",
       "12  0.07  0.07    0.557936\n",
       "13  0.07  0.07    0.551288\n",
       "14  0.09  0.09    0.546262\n",
       "15  0.09  0.09    0.523513\n",
       "16  0.11  0.11    0.510586\n",
       "17  0.11  0.11    0.482592\n",
       "18  0.12  0.12    0.481669\n",
       "19  0.12  0.12    0.480862\n",
       "20  0.13  0.13    0.456253\n",
       "21  0.13  0.13    0.437514\n",
       "22  0.15  0.15    0.423958\n",
       "23  0.15  0.15    0.412012\n",
       "24  0.16  0.16    0.408381\n",
       "25  0.16  0.16    0.392119\n",
       "26  0.17  0.17    0.391960\n",
       "27  0.17  0.17    0.382979\n",
       "28  0.18  0.18    0.379542\n",
       "29  0.20  0.20    0.376529\n",
       "30  0.22  0.22    0.356879\n",
       "31  0.24  0.24    0.331725\n",
       "32  0.26  0.26    0.327157\n",
       "33  0.27  0.27    0.320091\n",
       "34  0.27  0.27    0.309702\n",
       "35  0.30  0.30    0.301995\n",
       "36  0.33  0.33    0.277834\n",
       "37  0.33  0.33    0.275861\n",
       "38  0.38  0.38    0.246284\n",
       "39  0.40  0.40    0.224376\n",
       "40  0.40  0.40    0.223363\n",
       "41  0.41  0.41    0.217471\n",
       "42  0.43  0.43    0.209992\n",
       "43  0.44  0.44    0.203277\n",
       "44  0.46  0.46    0.198521\n",
       "45  0.49  0.49    0.183946\n",
       "46  0.49  0.49    0.174233\n",
       "47  0.52  0.52    0.165633\n",
       "48  0.55  0.55    0.164325\n",
       "49  0.59  0.59    0.150885\n",
       "50  0.61  0.61    0.150706\n",
       "51  0.63  0.63    0.144414\n",
       "52  0.68  0.68    0.123478\n",
       "53  0.68  0.68    0.119638\n",
       "54  0.69  0.69    0.118164\n",
       "55  0.71  0.71    0.111007\n",
       "56  0.72  0.72    0.110643\n",
       "57  0.75  0.75    0.106063\n",
       "58  0.78  0.78    0.099999\n",
       "59  0.80  0.80    0.098303\n",
       "60  0.91  0.91    0.060988\n",
       "61  0.93  0.93    0.060315\n",
       "62  1.00  1.00    0.025650"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'FPR':fpr,'TPR':fpr,'Thresholds':thresholds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "fig.suptitle('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8499074074074073\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
